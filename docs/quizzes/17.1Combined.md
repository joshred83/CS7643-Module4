# Quiz: Introduction to Reinforcement Learning





### Question 1 (True/False)

In reinforcement learning, agents are trained with labeled data to learn a direct mapping from inputs to outputs.

- [ ] A. True

- [ ] B. False

<details>
<summary>Show Answer</summary>

**Correct Answers:** B
**Explanation:**  
Unlike supervised learning, reinforcement learning does not rely on labeled data.  
> "We will not receive supervision in the form of the correct decision... instead, we will only receive evaluative feedback in the form of reward for the decision..."
</details>

---





### Question 2 (Multi-Select)

Which of the following accurately describe key characteristics and properties of reinforcement learning? (Select all that apply)

- [ ] A. Sequential decision-making in an environment with evaluative feedback

- [ ] B. Learning through trial and error

- [ ] C. Delayed feedback on the quality of decisions

- [ ] D. Learning optimal behavior through direct supervision

- [ ] E. Balancing exploration of new strategies with exploitation of known good strategies

- [ ] F. Receiving only rewards/penalties rather than correct action labels

<details>
<summary>Show Answer</summary>

**Correct Answers:** B
**Correct Answers:** ✅ Sequential decision-making with evaluative feedback, ✅ Learning through trial and error, ✅ Delayed feedback, ✅ Balancing exploration and exploitation, ✅ Receiving rewards/penalties not labels  
**Explanation:**  
Reinforcement learning involves multiple key characteristics beyond just the basic definition.  
> "Reinforcement learning can be defined in one sentence as a sequential decision making in an environment with evaluative feedback."
> "A key characteristic is that the agent receives delayed feedback, making it difficult to determine which actions led to rewards."
> "RL algorithms must balance exploration of new strategies with exploitation of known successful strategies."
</details>

---





### Question 3 (Multiple Select)

Which of the following are key characteristics or challenges of reinforcement learning?

- [ ] A. The agent receives a label for the correct action at each step

- [ ] B. The reward signal may be delayed

- [ ] C. The policy affects future data distribution

- [ ] D. Every state-action pair is observed multiple times

<details>
<summary>Show Answer</summary>

**Correct Answers:** The reward signal may be delayed, The policy affects future data distribution  
**Explanation:**  
RL faces unique challenges like delayed rewards and non-stationary data caused by policy updates.  
> "The reward may be delayed and it can only happen at the end of the task..."  
> "Any updates made to the policy... will change the data distribution... making this distribution non stationary."
</details>

---





### Question 4 (Multi-Select)

Which of the following accurately describe what an RL agent receives from the environment during the interaction loop? (Select all that apply)

- [ ] A. The next observation (state) after taking an action

- [ ] B. A reward signal that evaluates the action taken

- [ ] C. Information about which action would have been optimal

- [ ] D. The probability distribution over all possible next states

- [ ] E. The environment's internal state which may differ from the observation

- [ ] F. The time remaining until the episode terminates

<details>
<summary>Show Answer</summary>

**Correct Answers:** [Need to manually determine]
**Correct Answers:** ✅ The next observation/state, ✅ A reward signal  
**Explanation:**  
The agent receives both the new observation and the reward after taking an action, but not the other information.  
> "...the agent will receive an observation... it will execute an action... and produce a new observation... as well as a reward..."
> "The agent does not receive information about what the optimal action would have been, nor does it typically have access to the environment's full internal state."
</details>

---





### Question 5 (True/False)

The data distribution that a reinforcement learning agent sees remains stationary throughout training.

- [ ] A. True

- [ ] B. False

<details>
<summary>Show Answer</summary>

**Correct Answers:** B
**Explanation:**  
The data distribution is non-stationary because the policy changes what data the agent sees.  
> "...will change the data distribution of states and rewards... making this distribution non stationary."
</details>

---





### Question 6 (Multi-Select)

Which of the following accurately describe the nature and characteristics of "evaluative feedback" in reinforcement learning? (Select all that apply)

- [ ] A. Feedback is received in the form of a reward signal

- [ ] B. Feedback is only provided for actions actually taken, not hypothetical actions

- [ ] C. Feedback may be delayed, not immediate after each action

- [ ] D. Feedback provides a scalar value rather than a complete corrective instruction

- [ ] E. Feedback indicates the quality of an action, not the correct action itself

- [ ] F. Feedback is deterministic and consistent across all environments

<details>
<summary>Show Answer</summary>

**Correct Answers:** [Need to manually determine]
**Correct Answers:** ✅ Received as reward signal, ✅ Only provided for actions taken, ✅ May be delayed, ✅ Provides scalar value, ✅ Indicates quality not correctness  
**Explanation:**  
Evaluative feedback has multiple key characteristics that distinguish it from instructional feedback.  
> "Evaluative feedback means that the agent... receive rewards... only for the actions that it did take and not for the actions that did not take."
> "The reward signal merely evaluates actions, rather than instructing which action is correct."
> "The reward signal might be delayed, making it challenging to determine which action in a sequence led to a positive outcome."
</details>

---





### Question 7 (Multiple Select)

Which are common application domains for reinforcement learning as discussed in the lecture?

- [ ] A. Image segmentation

- [ ] B. Robotic control

- [ ] C. Atari game playing

- [ ] D. Board games like Go

<details>
<summary>Show Answer</summary>

**Correct Answers:** Robotic control, Atari game playing, Board games like Go  
**Explanation:**  
These specific applications are mentioned in the lecture.  
> "Here is an instance of a robotic control task..."  
> "RL applied to learn how to play Atari video games..."  
> "RL has also been applied to games like go..."
</details>

---





### Question 8 (True/False)

The RL agent receives rewards for all actions, including those it did not take.

- [ ] A. True

- [ ] B. False

<details>
<summary>Show Answer</summary>

**Correct Answers:** B
**Explanation:**  
Only actions that are actually taken receive rewards.  
> "...the agent is supposed to pick actions and receive rewards... only for the actions that it did take and not for the actions that did not take."
</details>

---





### Question 9 (Multi-Select)

Which of the following accurately describe challenges specific to reinforcement learning in real-world robotic settings? (Select all that apply)

- [ ] A. Some states may be seen only once

- [ ] B. Exploration can be dangerous or costly

- [ ] C. Real-world dynamics are often complex and difficult to model

- [ ] D. Hardware constraints limit computation speed

- [ ] E. Actions have physical consequences that cannot be reversed

- [ ] F. Reward signals may be sparse and difficult to design

<details>
<summary>Show Answer</summary>

**Correct Answers:** [Need to manually determine]
**Correct Answers:** ✅ States seen only once, ✅ Exploration can be dangerous/costly, ✅ Complex dynamics, ✅ Hardware constraints, ✅ Physical consequences, ✅ Sparse rewards  
**Explanation:**  
Real-world robotics faces numerous challenges that make RL particularly difficult.  
> "...the agent will see certain states only once and never again in his lifetime, making it difficult to learn from past mistakes."
> "In real-world settings, exploration can lead to physical damage, and the dynamics are often complex and difficult to model accurately."
> "The hardware constraints and physical consequences of actions create additional challenges not present in simulated environments."
</details>

---





### Question 10 (Multiple Choice)

What is the agent’s goal in reinforcement learning?

- [ ] A. Minimize classification error

- [ ] B. Memorize sequences of states

- [ ] C. Maximize long-term accumulated reward

- [ ] D. Discover

<details>
<summary>Show Answer</summary>

**Correct Answer:** Maximize long-term accumulated reward  
**Explanation:**  
The core objective of the agent is long-term reward maximization.  
> "The objective of this agent is to maximize the reward it will get from the environment in the long run."
</details>

