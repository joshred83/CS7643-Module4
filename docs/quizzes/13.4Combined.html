<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Quiz: Variational Autoencoders (VAEs) - CS7643 Module 4</title>
  <link rel="stylesheet" href="../css/styles.css">
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
  <div class="container">
    <div class="sidebar">
      <h2><a href="../index.html" style="color: white; text-decoration: none;">CS7643 Module 4</a></h2>
      <div class="topic-group">
        <h3>Generative Models</h3>
        <ul>
          <li><a href="13.1Combined.html">13.1 Introduction</a></li>
          <li><a href="13.2Combined.html">13.2 PixelRNN & PixelCNN</a></li>
          <li><a href="13.3Combined.html">13.3 GANs</a></li>
          <li><a href="13.4Combined.html">13.4 VAEs</a></li>
        </ul>
      </div>
      <div class="topic-group">
        <h3>Reinforcement Learning</h3>
        <ul>
          <li><a href="17.1Combined.html">17.1 Introduction</a></li>
          <li><a href="17.2Combined.html">17.2 MDPs</a></li>
          <li><a href="17.3Combined.html">17.3 Solving MDPs</a></li>
          <li><a href="17.4Combined.html">17.4 Deep Q-Learning</a></li>
          <li><a href="17.5Combined.html">17.5 Policy Gradients</a></li>
        </ul>
      </div>
      <div class="topic-group">
        <h3>Advanced Topics</h3>
        <ul>
          <li><a href="18.1Combined.html">18.1 Introduction</a></li>
          <li><a href="18.2Combined.html">18.2 Semi-Supervised</a></li>
          <li><a href="18.3Combined.html">18.3 Few-Shot</a></li>
          <li><a href="18.4Combined.html">18.4 Self-Supervised</a></li>
        </ul>
      </div>
      <div class="topic-group">
        <h3>Transcripts</h3>
        <ul>
          <li><a href="../transcripts/index.html">View All Transcripts</a></li>
        </ul>
      </div>
    </div>
    
    <div class="content">
      <h2 class="section-title">Quiz: Variational Autoencoders (VAEs)</h2>
  <div class="quiz-container">
    <div class="question" data-question-index="1">
      <h3>Question 1 (True/False)</h3>
      <p>VAEs are generative models that maintain an explicit density model of the data.</p>
      <div class="options">
        <div class="option">
          <input type="radio" id="q1-o0" name="q1" value="0" data-correct="true">
          <label for="q1-o0">A. True</label>
        </div>
        <div class="option">
          <input type="radio" id="q1-o1" name="q1" value="1" data-correct="false">
          <label for="q1-o1">B. False</label>
        </div>
      </div>
      <div class="feedback"></div>
      <button class="btn btn-check">Check Answer</button>
      <div class="explanation"><strong>Explanation:</strong>  
VAEs explicitly model the density function \( p(x) \), unlike GANs.  
<blockquote>"Variational autoencoders, which again are explicit density models, but that which have approximate densities."</blockquote></div>
    </div>
    <div class="question" data-question-index="2">
      <h3>Question 2 (Multi-Select)</h3>
      <p>Which of the following accurately describe the role and properties of the Variational Lower Bound (ELBO) in VAEs? (Select all that apply)</p>
      <div class="options">
        <div class="option">
          <input type="checkbox" id="q2-o0" name="q2" value="0" data-correct="true">
          <label for="q2-o0">A. It addresses the intractability of the marginal likelihood</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q2-o1" name="q2" value="1" data-correct="true">
          <label for="q2-o1">B. It allows for an indirect optimization of the log-likelihood</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q2-o2" name="q2" value="2" data-correct="true">
          <label for="q2-o2">C. It imposes a regularization effect on the latent space</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q2-o3" name="q2" value="3" data-correct="false">
          <label for="q2-o3">D. It enables direct sampling from the true posterior</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q2-o4" name="q2" value="4" data-correct="true">
          <label for="q2-o4">E. It provides a tractable objective function for optimization</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q2-o5" name="q2" value="5" data-correct="false">
          <label for="q2-o5">F. It completely eliminates the need for approximating the posterior</label>
        </div>
      </div>
      <div class="feedback"></div>
      <button class="btn btn-check">Check Answer</button>
      <div class="explanation"><strong>Explanation:</strong>  
The ELBO is used because computing the marginal likelihood directly is intractable, and it provides a lower bound that can be optimized.  
<blockquote>"Now, if we could directly maximize this, then we're essentially maximizing the likelihood... But we can't really do this. The integral doesn't allow us because it's intractable. Instead, what we're going to do is maximize what's called a variational lower bound..."</blockquote>
<blockquote>"The KL divergence term in the ELBO acts as a regularizer that constrains the approximate posterior to be close to the prior."</blockquote></div>
    </div>
    <div class="question" data-question-index="3">
      <h3>Question 3 (Multiple Select)</h3>
      <p>Which components are part of the VAE architecture?</p>
      <div class="options">
        <div class="option">
          <input type="checkbox" id="q3-o0" name="q3" value="0" data-correct="true">
          <label for="q3-o0">A. Encoder</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q3-o1" name="q3" value="1" data-correct="false">
          <label for="q3-o1">B. Discriminator</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q3-o2" name="q3" value="2" data-correct="true">
          <label for="q3-o2">C. Decoder</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q3-o3" name="q3" value="3" data-correct="true">
          <label for="q3-o3">D. Variational objective</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q3-o4" name="q3" value="4" data-correct="false">
          <label for="q3-o4">E. Contrastive loss</label>
        </div>
      </div>
      <div class="feedback"></div>
      <button class="btn btn-check">Check Answer</button>
      <div class="explanation"><strong>Explanation:</strong>  
VAEs consist of an encoder and decoder, trained using a variational lower bound (ELBO).  
<blockquote>"We'll have an encoder... a decoder... and a variational lower bound that we can compute."</blockquote></div>
    </div>
    <div class="question" data-question-index="4">
      <h3>Question 4 (Multi-Select)</h3>
      <p>Which of the following accurately describe the purpose and effects of the KL divergence term in the VAE loss function? (Select all that apply)</p>
      <div class="options">
        <div class="option">
          <input type="checkbox" id="q4-o0" name="q4" value="0" data-correct="true">
          <label for="q4-o0">A. It penalizes deviation of the learned distribution from the prior</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q4-o1" name="q4" value="1" data-correct="true">
          <label for="q4-o1">B. It acts as a regularizer on the latent space</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q4-o2" name="q4" value="2" data-correct="true">
          <label for="q4-o2">C. It ensures the latent space has a well-defined probability density</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q4-o3" name="q4" value="3" data-correct="false">
          <label for="q4-o3">D. It measures how well images are reconstructed</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q4-o4" name="q4" value="4" data-correct="true">
          <label for="q4-o4">E. It encourages a smooth, continuous latent space</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q4-o5" name="q4" value="5" data-correct="false">
          <label for="q4-o5">F. It forces the encoder to learn a specific fixed mapping</label>
        </div>
      </div>
      <div class="feedback"></div>
      <button class="btn btn-check">Check Answer</button>
      <div class="explanation"><strong>Explanation:</strong>  
The KL term ensures that the learned latent distribution does not deviate too far from the prior (typically Gaussian), which regularizes the latent space.  
<blockquote>"The second part of the term here, is a KL divergence between Q of z given x and p of z... And so we're taking the KL divergence between the Z's that our encoder network outputs and the prior..."</blockquote>
<blockquote>"This regularization ensures that the latent space has meaningful properties that allow for sampling and interpolation."</blockquote></div>
    </div>
    <div class="question" data-question-index="5">
      <h3>Question 5 (True/False)</h3>
      <p>The reparameterization trick enables backpropagation through the sampling process in VAEs.</p>
      <div class="options">
        <div class="option">
          <input type="radio" id="q5-o0" name="q5" value="0" data-correct="true">
          <label for="q5-o0">A. True</label>
        </div>
        <div class="option">
          <input type="radio" id="q5-o1" name="q5" value="1" data-correct="false">
          <label for="q5-o1">B. False</label>
        </div>
      </div>
      <div class="feedback"></div>
      <button class="btn btn-check">Check Answer</button>
      <div class="explanation"><strong>Explanation:</strong>  
The reparameterization trick allows the model to be differentiable despite sampling.  
<blockquote>"The problem is you can't actually back propagate through sampling... So there's something called a reparameterization trick... which allows you to do the sampling."</blockquote></div>
    </div>
    <div class="question" data-question-index="6">
      <h3>Question 6 (Multi-Select)</h3>
      <p>Which of the following accurately describe the properties and outputs of the decoder in a VAE? (Select all that apply)</p>
      <div class="options">
        <div class="option">
          <input type="checkbox" id="q6-o0" name="q6" value="0" data-correct="true">
          <label for="q6-o0">A. The decoder outputs parameters of a Gaussian distribution</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q6-o1" name="q6" value="1" data-correct="true">
          <label for="q6-o1">B. The decoder maps from latent space back to data space</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q6-o2" name="q6" value="2" data-correct="true">
          <label for="q6-o2">C. The decoder models the conditional probability p(x|z)</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q6-o3" name="q6" value="3" data-correct="false">
          <label for="q6-o3">D. The decoder uses a one-hot encoding for all outputs</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q6-o4" name="q6" value="4" data-correct="true">
          <label for="q6-o4">E. The decoder typically includes mean and variance parameters</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q6-o5" name="q6" value="5" data-correct="true">
          <label for="q6-o5">F. The decoder's parameters are learned through gradient descent</label>
        </div>
      </div>
      <div class="feedback"></div>
      <button class="btn btn-check">Check Answer</button>
      <div class="explanation"><strong>Explanation:</strong>  
The decoder outputs the mean and (diagonal) covariance of a Gaussian from which samples are drawn, mapping from latent to data space.  
<blockquote>"This decoder models p of x given z... it will be a Gaussian distribution parameter. Here specifically, it will be mu and Sigma."</blockquote>
<blockquote>"The decoder network transforms the latent representation back into the original data space and learns the parameters of the output distribution."</blockquote></div>
    </div>
    <div class="question" data-question-index="7">
      <h3>Question 7 (Multi-Select)</h3>
      <p>Which of the following are accurate statements about the relationship between the true posterior p(z|x) and the approximate posterior q(z|x) in VAEs? (Select all that apply)</p>
      <div class="options">
        <div class="option">
          <input type="checkbox" id="q7-o0" name="q7" value="0" data-correct="true">
          <label for="q7-o0">A. The true posterior p(z|x) cannot be computed directly due to intractability</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q7-o1" name="q7" value="1" data-correct="true">
          <label for="q7-o1">B. The approximate posterior q(z|x) is typically modeled as a Gaussian distribution</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q7-o2" name="q7" value="2" data-correct="true">
          <label for="q7-o2">C. The encoder network directly outputs parameters for q(z|x)</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q7-o3" name="q7" value="3" data-correct="true">
          <label for="q7-o3">D. The KL divergence term minimizes the difference between q(z|x) and p(z)</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q7-o4" name="q7" value="4" data-correct="true">
          <label for="q7-o4">E. The true posterior would require marginalization over all possible data points</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q7-o5" name="q7" value="5" data-correct="false">
          <label for="q7-o5">F. The approximation error between q(z|x) and p(z|x) can be quantified</label>
        </div>
      </div>
      <div class="feedback"></div>
      <button class="btn btn-check">Check Answer</button>
      <div class="explanation"><strong>Explanation:</strong>  
The true posterior is intractable, requiring an approximate posterior that is typically modeled as a Gaussian.  
<blockquote>"The right hand side is actually intractable. We can't compute this term. And so what we're going to do is... ignore it."</blockquote>
<blockquote>"What we're doing is using Q of z given x to approximate P of z given x."</blockquote>
<blockquote>"The encoder network produces parameters for the approximate posterior, typically modeled as a diagonal Gaussian."</blockquote></div>
    </div>
    <div class="question" data-question-index="8">
      <h3>Question 8 (Multiple Select)</h3>
      <p>Which benefits or capabilities are associated with the latent space of a trained VAE?</p>
      <div class="options">
        <div class="option">
          <input type="checkbox" id="q8-o0" name="q8" value="0" data-correct="true">
          <label for="q8-o0">A. Smooth interpolation between data points</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q8-o1" name="q8" value="1" data-correct="false">
          <label for="q8-o1">B. High-resolution image generation</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q8-o2" name="q8" value="2" data-correct="true">
          <label for="q8-o2">C. Disentanglement of semantic attributes</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q8-o3" name="q8" value="3" data-correct="true">
          <label for="q8-o3">D. Use in downstream tasks</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q8-o4" name="q8" value="4" data-correct="false">
          <label for="q8-o4">E. Fully deterministic reconstruction</label>
        </div>
      </div>
      <div class="feedback"></div>
      <button class="btn btn-check">Check Answer</button>
      <div class="explanation"><strong>Explanation:</strong>  
Latent space in VAEs supports interpolation and often learns disentangled, useful representations.</div>
    </div>
    <div class="question" data-question-index="9">
      <h3>Question 9 (True/False)</h3>
      <p>The decoder in a VAE directly generates the reconstructed image without involving any probability distribution.</p>
      <div class="options">
        <div class="option">
          <input type="radio" id="q9-o0" name="q9" value="0" data-correct="false">
          <label for="q9-o0">A. True</label>
        </div>
        <div class="option">
          <input type="radio" id="q9-o1" name="q9" value="1" data-correct="true">
          <label for="q9-o1">B. False</label>
        </div>
      </div>
      <div class="feedback"></div>
      <button class="btn btn-check">Check Answer</button>
      <div class="explanation"><strong>Explanation:</strong>  
The decoder actually outputs parameters of a probability distribution (typically Gaussian) from which the reconstruction is sampled.
<blockquote>"This decoder models p of x given z... it will be a Gaussian distribution parameter. Here specifically, it will be mu and Sigma."</blockquote></div>
    </div>
    <div class="question" data-question-index="10">
      <h3>Question 10 (Multi-Select)</h3>
      <p>Which of the following accurately describe limitations or challenges associated with VAEs, particularly when compared to other generative models? (Select all that apply)</p>
      <div class="options">
        <div class="option">
          <input type="checkbox" id="q10-o0" name="q10" value="0" data-correct="true">
          <label for="q10-o0">A. VAE samples tend to be blurrier than GAN samples</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q10-o1" name="q10" value="1" data-correct="true">
          <label for="q10-o1">B. VAEs can struggle with complex, high-dimensional data</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q10-o2" name="q10" value="2" data-correct="true">
          <label for="q10-o2">C. The Gaussian assumption in the latent space can be limiting</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q10-o3" name="q10" value="3" data-correct="true">
          <label for="q10-o3">D. VAEs prioritize reconstruction over sample quality</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q10-o4" name="q10" value="4" data-correct="false">
          <label for="q10-o4">E. VAEs cannot generate samples at all</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q10-o5" name="q10" value="5" data-correct="true">
          <label for="q10-o5">F. The KL divergence term can lead to posterior collapse</label>
        </div>
      </div>
      <div class="feedback"></div>
      <button class="btn btn-check">Check Answer</button>
      <div class="explanation"><strong>Explanation:</strong>  
VAEs often produce blurrier outputs due to the probabilistic nature of their objective function and struggle with various limitations.  
<blockquote>"VAEs can suffer from blurry outputs."</blockquote>
<blockquote>"The Gaussian assumption in both the prior and approximate posterior can limit the expressivity of the model."</blockquote>
<blockquote>"VAEs optimize for reconstruction quality which can come at the expense of sample quality."</blockquote></div>
    </div></div>
    </div>
  </div>
  <script src="../js/script.js"></script>
</body>
</html>