<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Quiz: PixelRNN & PixelCNN - CS7643 Module 4</title>
  <link rel="stylesheet" href="../css/styles.css">
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
  <div class="container">
    <div class="sidebar">
      <h2><a href="../index.html" style="color: white; text-decoration: none;">CS7643 Module 4</a></h2>
      <div class="topic-group">
        <h3>Generative Models</h3>
        <ul>
          <li><a href="13.1Combined.html">13.1 Introduction</a></li>
          <li><a href="13.2Combined.html">13.2 PixelRNN & PixelCNN</a></li>
          <li><a href="13.3Combined.html">13.3 GANs</a></li>
          <li><a href="13.4Combined.html">13.4 VAEs</a></li>
        </ul>
      </div>
      <div class="topic-group">
        <h3>Reinforcement Learning</h3>
        <ul>
          <li><a href="17.1Combined.html">17.1 Introduction</a></li>
          <li><a href="17.2Combined.html">17.2 MDPs</a></li>
          <li><a href="17.3Combined.html">17.3 Solving MDPs</a></li>
          <li><a href="17.4Combined.html">17.4 Deep Q-Learning</a></li>
          <li><a href="17.5Combined.html">17.5 Policy Gradients</a></li>
        </ul>
      </div>
      <div class="topic-group">
        <h3>Advanced Topics</h3>
        <ul>
          <li><a href="18.1Combined.html">18.1 Introduction</a></li>
          <li><a href="18.2Combined.html">18.2 Semi-Supervised</a></li>
          <li><a href="18.3Combined.html">18.3 Few-Shot</a></li>
          <li><a href="18.4Combined.html">18.4 Self-Supervised</a></li>
        </ul>
      </div>
      <div class="topic-group">
        <h3>Transcripts</h3>
        <ul>
          <li><a href="../transcripts/index.html">View All Transcripts</a></li>
        </ul>
      </div>
    </div>
    
    <div class="content">
      <h2 class="section-title">Quiz: PixelRNN & PixelCNN</h2>
  <div class="quiz-container">
    <div class="question" data-question-index="1">
      <h3>Question 1 (Multi-Select)</h3>
      <p>Which of the following accurately describe the use of the chain rule in probabilistic modeling for PixelRNN and PixelCNN? (Select all that apply)</p>
      <div class="options">
        <div class="option">
          <input type="checkbox" id="q1-o0" name="q1" value="0" data-correct="true">
          <label for="q1-o0">A. It decomposes the joint distribution of pixels into a product of conditional distributions</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q1-o1" name="q1" value="1" data-correct="true">
          <label for="q1-o1">B. It enables autoregressive generation of image pixels</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q1-o2" name="q1" value="2" data-correct="true">
          <label for="q1-o2">C. It requires an explicit ordering of image pixels</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q1-o3" name="q1" value="3" data-correct="false">
          <label for="q1-o3">D. It increases the computational efficiency of the models</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q1-o4" name="q1" value="4" data-correct="true">
          <label for="q1-o4">E. It allows modeling the probability of each pixel conditioned on previous pixels</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q1-o5" name="q1" value="5" data-correct="false">
          <label for="q1-o5">F. It eliminates the need for neural networks in image generation</label>
        </div>
      </div>
      <div class="feedback"></div>
      <button class="btn btn-check">Check Answer</button>
      <div class="explanation">(A) into manageable conditional probabilities. This enables autoregressive generation (B) where each pixel depends on previously generated ones. The approach requires defining an explicit pixel ordering (C) and allows modeling each pixel's probability conditioned on previous pixels (E). However, it doesn't improve computational efficiency (D) - in fact, generation is sequential and slow. Neural networks are still essential (F) for modeling the complex conditional distributions.

<blockquote>"We can factorize the joint distribution as the product of conditionals, where we define some ordering over the pixels."</blockquote>
<blockquote>"Using the chain rule, we can compute the joint probability of all pixels by decomposing it into a product of conditional probabilities."</blockquote></div>
    </div>
    <div class="question" data-question-index="2">
      <h3>Question 2 (True/False)</h3>
      <p>In PixelRNN, the generation of an image can be parallelized to improve efficiency.</p>
      <div class="options">
        <div class="option">
          <input type="radio" id="q2-o0" name="q2" value="0" data-correct="false">
          <label for="q2-o0">A. True</label>
        </div>
        <div class="option">
          <input type="radio" id="q2-o1" name="q2" value="1" data-correct="true">
          <label for="q2-o1">B. False</label>
        </div>
      </div>
      <div class="feedback"></div>
      <button class="btn btn-check">Check Answer</button>
      <div class="explanation">'s autoregressive nature means each pixel depends on previously generated pixels, forcing the generation process to be sequential. This inherent sequential dependency makes parallelization impossible during the generation phase, resulting in slow sampling.

<blockquote>"This can be really slow, unlike convolution layers it's not parallelized."</blockquote></div>
    </div>
    <div class="question" data-question-index="3">
      <h3>Question 3 (Multi-Select)</h3>
      <p>Which of the following challenges are associated with modeling images using PixelRNN? (Select all that apply)</p>
      <div class="options">
        <div class="option">
          <input type="checkbox" id="q3-o0" name="q3" value="0" data-correct="true">
          <label for="q3-o0">A. Sequential generation leading to slow sampling processes</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q3-o1" name="q3" value="1" data-correct="false">
          <label for="q3-o1">B. Computational intensity of recurrent neural networks</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q3-o2" name="q3" value="2" data-correct="true">
          <label for="q3-o2">C. Difficulty in capturing long-range dependencies effectively</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q3-o3" name="q3" value="3" data-correct="true">
          <label for="q3-o3">D. Inability to model complex data distributions</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q3-o4" name="q3" value="4" data-correct="false">
          <label for="q3-o4">E. Lack of parallelization during generation</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q3-o5" name="q3" value="5" data-correct="false">
          <label for="q3-o5">F. Vanishing gradients in long sequences</label>
        </div>
      </div>
      <div class="feedback"></div>
      <button class="btn btn-check">Check Answer</button>
      <div class="explanation">: it generates pixels sequentially which results in slow sampling (A); recurrent neural networks are computationally intensive (B); the generation process cannot be parallelized (E); and the RNN architecture can suffer from vanishing gradients when handling long sequences (F). However, PixelRNN is actually designed to capture long-range dependencies (C is incorrect) through its recurrent structure, and it is quite capable of modeling complex data distributions (D is incorrect) - this is one of its strengths.

<blockquote>"This can be really slow, unlike convolution layers it's not parallelized."</blockquote>
<blockquote>"The RNN is computationally more intensive and sequential by nature, which creates challenges when generating high-resolution images."</blockquote></div>
    </div>
    <div class="question" data-question-index="4">
      <h3>Question 4 (Multi-Select)</h3>
      <p>What are the key architectural and functional differences between PixelCNN and PixelRNN? (Select all that apply)</p>
      <div class="options">
        <div class="option">
          <input type="checkbox" id="q4-o0" name="q4" value="0" data-correct="true">
          <label for="q4-o0">A. PixelCNN uses masked convolutions, while PixelRNN uses recurrent neural networks</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q4-o1" name="q4" value="1" data-correct="true">
          <label for="q4-o1">B. PixelCNN allows for more parallelization during training</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q4-o2" name="q4" value="2" data-correct="false">
          <label for="q4-o2">C. PixelRNN typically has better modeling capacity for long-range dependencies</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q4-o3" name="q4" value="3" data-correct="false">
          <label for="q4-o3">D. PixelCNN uses recurrent layers, while PixelRNN uses convolutional layers</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q4-o4" name="q4" value="4" data-correct="true">
          <label for="q4-o4">E. PixelCNN is generally faster during training but still sequential during generation</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q4-o5" name="q4" value="5" data-correct="false">
          <label for="q4-o5">F. PixelRNN creates an implicit ordering of pixels, while PixelCNN requires an explicit ordering</label>
        </div>
      </div>
      <div class="feedback"></div>
      <button class="btn btn-check">Check Answer</button>
      <div class="explanation">: PixelCNN uses masked convolutions while PixelRNN uses recurrent neural networks (A); PixelCNN's architecture allows for greater parallelization during training (B), making it computationally more efficient; PixelRNN has superior capacity for modeling long-range dependencies (C) due to its recurrent structure; and PixelCNN offers faster training though both models remain sequential during the actual generation phase (E). Option D incorrectly reverses the architectures. Option F is incorrect as both models require an explicit pixel ordering - this ordering is a fundamental requirement of autoregressive models.

<blockquote>"We can train this using similar methods as the language models, for example, a recurrent neural network."</blockquote>
<blockquote>"This can be really slow, unlike convolution layers it's not parallelized."</blockquote>
<blockquote>"PixelCNN is actually our early attempt to replace the RNN in PixelRNN with a more efficient CNN based architecture."</blockquote></div>
    </div>
    <div class="question" data-question-index="5">
      <h3>Question 5 (True/False)</h3>
      <p>Masked convolutions in PixelCNN allow the model to capture dependencies between all pixels in an image simultaneously.</p>
      <div class="options">
        <div class="option">
          <input type="radio" id="q5-o0" name="q5" value="0" data-correct="false">
          <label for="q5-o0">A. True</label>
        </div>
        <div class="option">
          <input type="radio" id="q5-o1" name="q5" value="1" data-correct="true">
          <label for="q5-o1">B. False</label>
        </div>
      </div>
      <div class="feedback"></div>
      <button class="btn btn-check">Check Answer</button>
      <div class="explanation">. They enforce the autoregressive property by ensuring each pixel can only depend on previously generated pixels (those above and to the left in raster scan order). This maintains the sequential nature of generation where each pixel is conditioned only on pixels that came before it, not on all pixels simultaneously.

<blockquote>"We'd like to make sure that when predicting a particular pixel, we're only using information from pixels that are above and to the left of the current pixel."</blockquote>
<blockquote>"The causal structure is enforced by masking certain elements of the convolution kernel so that a pixel cannot see the future pixels that are below or to the right."</blockquote></div>
    </div>
    <div class="question" data-question-index="6">
      <h3>Question 6 (Multiple Choice)</h3>
      <p>Which of the following is a drawback of using PixelRNN for image generation?</p>
      <div class="options">
        <div class="option">
          <input type="radio" id="q6-o0" name="q6" value="0" data-correct="false">
          <label for="q6-o0">A. It cannot model the joint distribution of pixels.</label>
        </div>
        <div class="option">
          <input type="radio" id="q6-o1" name="q6" value="1" data-correct="false">
          <label for="q6-o1">B. It lacks the capacity to learn from data.</label>
        </div>
        <div class="option">
          <input type="radio" id="q6-o2" name="q6" value="2" data-correct="true">
          <label for="q6-o2">C. It requires sequential processing, making it less efficient.</label>
        </div>
        <div class="option">
          <input type="radio" id="q6-o3" name="q6" value="3" data-correct="false">
          <label for="q6-o3">D. It ignores the spatial structure of images.</label>
        </div>
      </div>
      <div class="feedback"></div>
      <button class="btn btn-check">Check Answer</button>
      <div class="explanation">. In contrast, options A, B, and D are incorrect: PixelRNN successfully models the joint distribution of pixels through autoregressive factorization; it has strong learning capacity from data; and it explicitly accounts for spatial image structure through its pixel ordering scheme.

<blockquote>"This can be really slow, unlike convolution layers it's not parallelized."</blockquote>
<blockquote>"Using an RNN, a recurrent neural network, the idea is that we're going to follow some ordering."</blockquote></div>
    </div>
    <div class="question" data-question-index="7">
      <h3>Question 7 (Multiple Choice)</h3>
      <p>What role does teacher forcing play in training PixelRNN models?</p>
      <div class="options">
        <div class="option">
          <input type="radio" id="q7-o0" name="q7" value="0" data-correct="false">
          <label for="q7-o0">A. It allows the model to generate images without any input.</label>
        </div>
        <div class="option">
          <input type="radio" id="q7-o1" name="q7" value="1" data-correct="true">
          <label for="q7-o1">B. It uses actual image pixels to guide the model's predictions during training.</label>
        </div>
        <div class="option">
          <input type="radio" id="q7-o2" name="q7" value="2" data-correct="false">
          <label for="q7-o2">C. It forces the model to learn pixel dependencies without supervision.</label>
        </div>
        <div class="option">
          <input type="radio" id="q7-o3" name="q7" value="3" data-correct="false">
          <label for="q7-o3">D. It enables the model to bypass the need for a defined pixel ordering.</label>
        </div>
      </div>
      <div class="feedback"></div>
      <button class="btn btn-check">Check Answer</button>
      <div class="explanation">(real image pixels) rather than its own predictions. This stabilizes training by preventing error accumulation. Options A, C, and D are incorrect characterizations of teacher forcing.

<blockquote>"We can train this using similar methods as the language models, for example, a recurrent neural network."</blockquote>
<blockquote>"At training time, we have an image and we want to maximize the likelihood of that image."</blockquote></div>
    </div>
    <div class="question" data-question-index="8">
      <h3>Question 8 (Multi-Select)</h3>
      <p>What are the advantages of using PixelCNN over PixelRNN for image generation tasks? (Select all that apply)</p>
      <div class="options">
        <div class="option">
          <input type="checkbox" id="q8-o0" name="q8" value="0" data-correct="true">
          <label for="q8-o0">A. PixelCNN allows for parallel processing during training, improving efficiency</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q8-o1" name="q8" value="1" data-correct="true">
          <label for="q8-o1">B. PixelCNN has a simpler architecture that is easier to implement</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q8-o2" name="q8" value="2" data-correct="true">
          <label for="q8-o2">C. PixelCNN uses convolutional operations which are better optimized in modern deep learning frameworks</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q8-o3" name="q8" value="3" data-correct="false">
          <label for="q8-o3">D. PixelCNN inherently captures long-range dependencies better than PixelRNN</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q8-o4" name="q8" value="4" data-correct="true">
          <label for="q8-o4">E. PixelCNN requires less memory during training</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q8-o5" name="q8" value="5" data-correct="false">
          <label for="q8-o5">F. PixelCNN converges faster during the training process</label>
        </div>
      </div>
      <div class="feedback"></div>
      <button class="btn btn-check">Check Answer</button>
      <div class="explanation">: it enables parallel processing during training (A), significantly improving computational efficiency; it employs a simpler architecture based on CNNs rather than RNNs (B), making implementation more straightforward; it leverages convolutional operations that are highly optimized in modern deep learning frameworks (C); and it typically requires less memory during training (E) due to its architecture. Option D is incorrect - PixelRNN actually has better capacity for modeling long-range dependencies than PixelCNN. Option F is not necessarily true in all cases - while training may be faster per epoch, convergence depends on multiple factors beyond architecture.

<blockquote>"This can be really slow, unlike convolution layers it's not parallelized."</blockquote>
<blockquote>"PixelCNN is actually our early attempt to replace the RNN in PixelRNN with a more efficient CNN based architecture."</blockquote>
<blockquote>"The drawback is that the CNN might not be as good as the RNN regarding its capacity to model long range dependencies."</blockquote></div>
    </div>
    <div class="question" data-question-index="9">
      <h3>Question 9 (True/False)</h3>
      <p>PixelRNN and PixelCNN are both designed to model the joint distribution of image pixels by factorizing it into conditional distributions.</p>
      <div class="options">
        <div class="option">
          <input type="radio" id="q9-o0" name="q9" value="0" data-correct="false">
          <label for="q9-o0">A. True</label>
        </div>
        <div class="option">
          <input type="radio" id="q9-o1" name="q9" value="1" data-correct="true">
          <label for="q9-o1">B. False</label>
        </div>
      </div>
      <div class="feedback"></div>
      <button class="btn btn-check">Check Answer</button>
      <div class="explanation">: they factorize the joint probability distribution of all pixels into a product of conditional distributions. This autoregressive approach allows both models to estimate the probability of each pixel conditioned on previously generated pixels, following a specific ordering. Their core difference lies in how they implement this conditioning (RNNs vs. masked convolutions), not in the probabilistic framework they employ.

<blockquote>"We can factorize the joint distribution as the product of conditionals, where we define some ordering over the pixels."</blockquote>
<blockquote>"Using the chain rule, we can compute the joint probability of all pixels by decomposing it into a product of conditional probabilities."</blockquote></div>
    </div>
    <div class="question" data-question-index="10">
      <h3>Question 10 (Multi-Select)</h3>
      <p>Which of the following accurately describe the significance and implications of pixel ordering in PixelRNN and PixelCNN models? (Select all that apply)</p>
      <div class="options">
        <div class="option">
          <input type="checkbox" id="q10-o0" name="q10" value="0" data-correct="true">
          <label for="q10-o0">A. It enables the decomposition of the joint pixel distribution into a sequence of conditional probabilities</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q10-o1" name="q10" value="1" data-correct="false">
          <label for="q10-o1">B. It determines which pixels can influence the prediction of subsequent pixels</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q10-o2" name="q10" value="2" data-correct="false">
          <label for="q10-o2">C. It affects the receptive field of the model's architecture</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q10-o3" name="q10" value="3" data-correct="true">
          <label for="q10-o3">D. It allows the models to bypass the need for training data</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q10-o4" name="q10" value="4" data-correct="false">
          <label for="q10-o4">E. It creates a directed dependency graph among image pixels</label>
        </div>
        <div class="option">
          <input type="checkbox" id="q10-o5" name="q10" value="5" data-correct="false">
          <label for="q10-o5">F. It impacts the model's ability to capture spatial relationships in the image</label>
        </div>
      </div>
      <div class="feedback"></div>
      <button class="btn btn-check">Check Answer</button>
      <div class="explanation">. It enables factorizing the joint distribution into conditional probabilities (A), directly determines which pixels can influence later predictions (B), affects the architecture's receptive field design (C), creates a directed dependency graph between pixels (E), and influences how the model captures spatial relationships (F). Option D is incorrect - pixel ordering has no impact on the need for training data; these models still require substantial training data regardless of the chosen ordering scheme.

<blockquote>"We can factorize the joint distribution as the product of conditionals, where we define some ordering over the pixels."</blockquote>
<blockquote>"Using an RNN, a recurrent neural network, the idea is that we're going to follow some ordering."</blockquote>
<blockquote>"To maintain causality, we need to make sure that the prediction for a pixel only depends on pixels that are already in the sequence."</blockquote></div>
    </div></div>
    </div>
  </div>
  <script src="../js/script.js"></script>
</body>
</html>