# Quiz: Generative Models - Deep Dive





### Question 1 (Multi-Select)


Which of the following accurately describe the role and goals of generative models in unsupervised learning?

- [ ] A. They only classify input data into known categories.

- [ ] B. They estimate the probability distribution over the input space.

- [ ] C. They can be used to generate new, artificial samples resembling the data.

- [ ] D. They are used for tasks such as density estimation.

- [ ] E. They require labeled data to function effectively.

<details>
<summary>Show Answer</summary>

**Correct Answers:** 
**Explanation:**  
Generative models do **not require labeled data** and **do more than classification**.

> "Here we take a probabilistic view of unsupervised learning and try to estimate the probability distribution over the input space."  
> "In this lesson, we'll focus on Density Estimation... we may want to just have the ability to generate samples from this distribution..."
</details>



### Question 2 (Multiple Choice)


Which traditional method was used for density estimation before the resurgence of deep learning, despite its limitations with high-dimensional data?

- [ ] A. Naive Bayes classifiers

- [ ] B. Support Vector Machines

- [ ] C. Gaussian Mixture Models

- [ ] D. Linear Discriminant Analysis

<details>
<summary>Show Answer</summary>

**Correct Answers:** 
**Explanation:**  
GMMs were traditionally used, though they struggle with high-dimensional input spaces.

> "For example, Gaussian mixture models also produce some estimate of the probability distribution over the input space. However, these methods have severe deficiencies when the input is very high dimensional."
</details>



### Question 3 (True/False)


Generative models model the conditional probability of labels given the input data.

- [ ] A. True

- [ ] B. False

<details>
<summary>Show Answer</summary>

**Correct Answers:** 
**Explanation:**  
Discriminative models model \( P(y|x) \); generative models model \( P(x) \).

> "Discriminative models, model the conditional distribution probability of the label given the input... Generative models, on the other hand, model the distribution over the input space."
</details>



### Question 4 (Multi-Select)


What are key challenges associated with modeling the joint distribution of high-dimensional data in generative models?

- [ ] A. High computational complexity

- [ ] B. Intractability of the exact probability distribution

- [ ] C. Lack of any theoretical basis

- [ ] D. Requirement of assumptions or simplifications

<details>
<summary>Show Answer</summary>

**Correct Answers:** 
**Explanation:**  
Modeling \( P(x) \) directly is challenging without simplifying assumptions.

> "This is a very intractable and hard thing to do. And so we'll have to make various assumptions or simplifications in order to make this feasible."
</details>



### Question 5 (Concept Application)


You are asked to design a generative model for a new high-dimensional image dataset. What strategies from the transcript are likely to help in tackling the complexity?

- [ ] A. Use deep learning architectures that reduce dimensionality

- [ ] B. Use rule-based symbolic reasoning

- [ ] C. Leverage embeddings to find low-dimensional representations

- [ ] D. Avoid simplifications to maintain full generality

<details>
<summary>Show Answer</summary>

**Correct Answers:** 
**Explanation:**  
The transcript emphasizes dimensionality reduction using neural networks.

> "Deep learning is very good at learning features that extract meaningful information in a low dimensional embedding from high dimensional data."
</details>



### Question 6 (Multiple Choice)


Which of the following statements best captures the distinction between discriminative and generative models?

- [ ] A. Discriminative models generate new samples from the data distribution.

- [ ] B. Generative models are always more accurate than discriminative ones.

- [ ] C. Discriminative models estimate \( P(y|x) \), while generative models estimate \( P(x) \).

- [ ] D. Generative models require supervised data, while discriminative models do not.

<details>
<summary>Show Answer</summary>

**Correct Answers:** 
**Explanation:**  
This is a central distinction made in the lesson.

> "Discriminative models, model the conditional distribution probability of the label given the input... Generative models... model the distribution over the input space."
</details>



### Question 7 (Multi-Select)


According to the transcript, why is deep learning suitable for generative modeling of high-dimensional data?

- [ ] A. Deep learning methods can extract meaningful low-dimensional features.

- [ ] B. Neural networks can model complex distributions with sufficient flexibility.

- [ ] C. They inherently encode explicit probabilistic rules.

- [ ] D. They eliminate the need for any data preprocessing.

<details>
<summary>Show Answer</summary>

**Correct Answers:** 
**Explanation:**  
Deep learning reduces dimensionality and provides flexibility in modeling.

> "Deep learning is very good at learning features that extract meaningful information in a low dimensional embedding..."  
> "Just, like discriminative models we can have a parametric approximation of this distribution."
</details>



### Question 8 (True/False)


The ability to generate new data samples is a core feature of generative models.

- [ ] A. True

- [ ] B. False

<details>
<summary>Show Answer</summary>

**Correct Answers:** 
**Explanation:**  
Generating samples is one of the core applications.

> "We may want to just have the ability to generate samples from this distribution, that is actually generate artificial examples..."
</details>



### Question 9 (Multiple Choice)


Which principle is often used to optimize the parameters of generative models?

- [ ] A. Cross-entropy minimization

- [ ] B. Maximum likelihood estimation

- [ ] C. Mean squared error

- [ ] D. KL divergence minimization

<details>
<summary>Show Answer</summary>

**Correct Answers:** 
**Explanation:**  
MLE is the optimization principle used for learning generative models.

> "We can have a set of parameterized models \( p(x, \theta) \)... use the principle of maximum likelihood
</details>