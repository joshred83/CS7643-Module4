<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>18.4 Unsupervised and Self-Supervised Learning - CS7643 Module 4</title>
  <link rel="stylesheet" href="../css/styles.css">
</head>
<body>
  <div class="container">
    <div class="sidebar">
      <h2><a href="../index.html" style="color: white; text-decoration: none;">CS7643 Module 4</a></h2>
      <div class="topic-group">
        <h3>Generative Models</h3>
        <ul>
          <li><a href="13.1Combined.html">13.1 Introduction</a></li>
          <li><a href="13.2Combined.html">13.2 PixelRNN & PixelCNN</a></li>
          <li><a href="13.3Combined.html">13.3 GANs</a></li>
          <li><a href="13.4Combined.html">13.4 VAEs</a></li>
        </ul>
      </div>
      <div class="topic-group">
        <h3>Reinforcement Learning</h3>
        <ul>
          <li><a href="17.1Combined.html">17.1 Introduction</a></li>
          <li><a href="17.2Combined.html">17.2 MDPs</a></li>
          <li><a href="17.3Combined.html">17.3 Solving MDPs</a></li>
          <li><a href="17.4-Combined.html">17.4 Deep Q-Learning</a></li>
          <li><a href="17.5Combined.html">17.5 Policy Gradients</a></li>
        </ul>
      </div>
      <div class="topic-group">
        <h3>Advanced Topics</h3>
        <ul>
          <li><a href="18.1Combined.html">18.1 Introduction</a></li>
          <li><a href="18.2Combined.html">18.2 Semi-Supervised</a></li>
          <li><a href="18.3Combined.html">18.3 Few-Shot</a></li>
          <li><a href="18.4Combined.html">18.4 Self-Supervised</a></li>
        </ul>
      </div>
      <div class="topic-group">
        <h3>Transcripts</h3>
        <ul>
          <li><a href="../transcripts/index.html">View All Transcripts</a></li>
        </ul>
      </div>
    </div>
    
    <div class="content">
      
        <h2 class="section-title">18.4 Unsupervised and Self-Supervised Learning</h2>
        <div class="transcript-container">
          <div class="transcript">
            <p><span class="timestamp">[00:00:00]</span>
>> In this lesson, we'll talk about unsupervised and self supervised learning, where we have only unlabeled data, and we'd like to learn effective feature representations, so that we can fine tune them for downstream tasks. For supervised learning, we have explored a number of architectures and last function in order to optimize this task.</p><p><span class="timestamp">[00:00:21]</span>
For classification, we often use fully connected networks at the end, which are then converted to probabilities through softmax, and we use the cross entropy loss. For regression tasks, we can use other loss functions, such as mean squared error. The key is that we have labels and these labels allow us to compute these loss functions, and we can use that to back propagate through the network to update the parameters.</p><p><span class="timestamp">[00:00:45]</span>
In unsupervised learning, there's a set of traditional tasks that we may want to perform. For example, we may want to perform clustering where the output is a set of clusters or groupings of data, where similar pieces of data are grouped into the same cluster, and this similar pieces of data are grouped into different clusters.</p><p><span class="timestamp">[00:01:04]</span>
We may just want to learn effective features typically reduced dimensionality from the input. Here, dimensionality reduction has been looked at widely even before deep learning. And we just want to convert x the input into some latent feature representation z, or we may want to perform density estimation that is we want to model the joint distribution over the inputs.</p><p><span class="timestamp">[00:01:27]</span>
In this lesson, we'll specifically talk about dimensionality reduction. That is, how can we perform effective feature learning, such that we can then optimize them or fine tune them for downstream tasks, we may talk a little bit about clustering as well. And in later lessons, we'll talk about density estimation specifically using generative models.</p><p><span class="timestamp">[00:01:48]</span>
Unlike supervised learning, unsupervised learning only has the raw data as input, and so there's many things that we may want to learn. And it's not clear what is the loss function that we can use to drive this learning, so that's the key question. What can we possibly do with no labels at all, especially in deep learning, where everything is formed through the loss function, which drives the gradients to update our parameters.</p><p><span class="timestamp">[00:02:15]</span>
One such task that we can use in order to learn feature representations that are effective is an outer encoder. Here, we'll use the same encoder decoder architectures that we've talked about throughout, in order to first convert the image into a small low dimensional compressed vector that is features.</p><p><span class="timestamp">[00:02:35]</span>
These features are low dimensional embeddings that represent, hopefully the most important aspects of the image. Given this bottleneck features, we'll perform a decoding step, we'll perform a reconstruction task that is, we'll just try to reconstruct the input. This may seem strange, we already have the input, there's no actual need to reconstruct the input.</p><p><span class="timestamp">[00:02:57]</span>
But we're forcing the neural network to learn really effective low dimensional embeddings that capture important aspects of the input. Once we train the system, we can actually get rid of the encoder and just use the low dimensional embedding in order to for example, fine tune it to a labeled classification task.</p><p><span class="timestamp">[00:03:16]</span>
Again, the key thing is that here we can do this without any labels at all. We know what the input is, we want to reconstruct it, we don't need any labels. And this also allows us to use a very concrete loss function, that is we can minimize the difference with mean squared error for example, between the input and the reconstructed input.</p><p><span class="timestamp">[00:03:35]</span>
One of the key ideas here is the bottleneck in the middle, if that bottleneck is too powerful that it's, for example, the dimensionality is equal to the input, then actually the neural network can learn to just mimic the input. That is, it can learn the identity function, the key idea is that we're forcing it to compress the information into a small low dimensional embedding.</p><p><span class="timestamp">[00:03:57]</span>
Once we have effective feature representations, we can then use those features and add another linear layer, in order to perform a classification task on a new task that we may have a small number of labeled examples for. Again, the key idea is that we can pre-train these features on large sets of unlabeled data and fine tune them to a smaller data set.</p><p><span class="timestamp">[00:04:19]</span>
And in many cases, we can also freeze the encoder as well, if we don't have enough data to fine tune them. In that case, we're only updating the classifier layer on a smaller number of parameters using the small amount of data. Another thing we can leverage is the clustering assumption.</p><p><span class="timestamp">[00:04:35]</span>
This is common in unsupervised learning, where we assume that high density regions form clusters, that is items or instances that are similar form groups or clumps in some feature space. While low density region, that is regions where there's not a lot of examples separate clusters, which hold semantic meaning.</p><p><span class="timestamp">[00:04:56]</span>
The key idea is that whatever feature space we learned, we'd like those feature spaces to have these kinds of characteristics. We'd like them to essentially have features that are similar to similar items and features that are far apart, according to some distance metric or elements that are different.</p><p><span class="timestamp">[00:05:16]</span>
And so, this is what we're hoping, we're hoping that essentially whatever original feature space or raw input space we feed. Once we've output feature space that's transformed using a deep neural network, we'd like that feature space to have this property. One thing that we can test this property with is apply K-Mean.</p><p><span class="timestamp">[00:05:36]</span>
For example, we can just optimize some neural network using for example, auto-encoders, and then see how well they partition the space. And we can use things like T-Snee, which we've discussed before in order to visualize these feature spaces as well. We can learn an algorithm directly using this principle that can extract or learn features in an unsupervised manner.</p><p><span class="timestamp">[00:05:58]</span>
Specifically, we'll take the unlabeled data and feed it through a randomly initialized convolutional neural network. These features will be pretty noisy, but hopefully things that are somewhat semantically similar will have somewhat similar features. We'll take all of these features for a set of unlabeled data and apply an unsupervised clustering algorithm such as K-Means, unlike a CNN, K-Means takes the global structure of the feature space into account.</p><p><span class="timestamp">[00:06:26]</span>
So it will group things that tend to be similar in the feature space into one cluster, and things that are dissimilar into different clusters. And we'll use this just as we did in semi-supervised learning as pseudo-labels, that is ground truth quote unquote, labels that we use to drive backpropagation.</p><p><span class="timestamp">[00:06:42]</span>
So the CNN will also have a set of linear and nonlinear, fully connected layers, and Softmax function in order to make probabilistic predictions, and then we'll essentially have backpropagation through this prediction. The key idea is that, forcing the neural network to group things that are somewhat similar in the beginning in feature space together, and very dissimilar apart, will improve the features.</p><p><span class="timestamp">[00:07:08]</span>
And then we'll do further iterations, we'll take the new features and then apply unsupervised clustering again. And again, this hopefully will produce even better clusters, and hence better pseudo-labels and then that will drive better feature learning and so on. Now, this loop will hopefully reinforce itself to drive the features to be better and better, of course, there might be some issues.</p><p><span class="timestamp">[00:07:33]</span>
For example, you might have things like empty clusters. If the neural network essentially predicts that everything is in one cluster, then it can do really well and essentially have trivial parameterization that always outputs the same thing. You can also have things like imbalance if there's only one item per cluster for most of the clusters, and then one cluster has a lot of things.</p><p><span class="timestamp">[00:07:54]</span>
Then it will just learn again to output that large cluster. And so, this is a delicate balance between the feature learning part and the clustering part. But there are several engineering that you can do that are described in this paper which we won't go through in order to try to balance this optimization.</p><p><span class="timestamp">[00:08:12]</span>
And in the end, really learn effective feature representations using unlabeled data alone. While a lot of these tasks have already existed before deep learning, for example, reconstruction is an optimization criteria for principal component analysis. And clustering has long existed before deep learning, we can actually generalize this idea into the concept of surrogate tasks.</p><p><span class="timestamp">[00:08:35]</span>
That is we'd like to come up with tasks where we can get the answer or label for free in order to drive optimization and prevent the need for human annotation. These tasks though, must also force the neural network to learn effective feature representation. And we'd like to engineer the tasks so that there aren't any trivial solutions or ways that the neural network can cheat to prevent it from learning effective feature representation.</p><p><span class="timestamp">[00:09:02]</span>
It turns out that over the years, a large number of such tasks have been devised, and they all have different characteristics in terms of how effective the features that are learned are. And this can differ both in terms of the level at which the neural network learns features.</p><p><span class="timestamp">[00:09:17]</span>
For example, low-level edge features versus high-level semantic features, as well as how well they can generalize to other tasks as well. One example is colorization. Given a red, green, blue three channel image, we can actually just convert it to grayscale. This can be done using a hard coded formula.</p><p><span class="timestamp">[00:09:36]</span>
And the input to a neural network will then be this grayscale image. And we'd like it to re-colorize the image. Now clearly, this forces the neural network to have to understand something about what is in the image. Otherwise it's really hard to colorize. For example, if you don't know that this is a fish or what type of fish it is or if you have other objects such as tennis balls and so on, it's going to be really hard to apply the same color.</p><p><span class="timestamp">[00:10:00]</span>
And what's nice is that we know the answer, we already have the original RGB image. And so we can have the neural network predicts the colorized image and we can use for example, a mean squared error loss function to drive feature learning. Another example is a jigsaw puzzle.</p><p><span class="timestamp">[00:10:18]</span>
We can take an image and separate it into nine chunks that are nonoverlapping and so the input here is a set of image patches. But we don't give it the order of the image patches. Given to such image patches, let's say the center one and another one, we'd like to predict the discrete image patch location of the second one relative to the center.</p><p><span class="timestamp">[00:10:41]</span>
And so you could see this as a cross-entropy loss across eight different positions because for each image patch, you want to know which of the eight non-center positions it's located in. Again, in order to put this together, the neural network has to form some representation that represents what is in the image in a semantically meaningful manner.</p><p><span class="timestamp">[00:11:04]</span>
Another one that's interesting is rotation prediction. We can have unlabeled images that we apply various rotations to, for example, we can have four discrete rotations. We then apply all of these rotations and force the neural network to predict what rotation we perform and so the output is the prediction of the rotation amount.</p><p><span class="timestamp">[00:11:25]</span>
Again, because it's discrete, we could use a cross entropy-classification loss. Again, this is a task that we don't really care about in the real world but will drive the neural network to learn effective features. There's a specific way that we evaluate the results of these surrogate tasks. Specifically, what we'd like to do is answer the question how good are the feature representations that we learn in an unsupervised manner and how well do they generalize to new label tasks.</p><p><span class="timestamp">[00:11:55]</span>
And so what we typically do is just take the encoder part, for example in the rotation prediction, we don't actually care about the layer that actually predicts the rotation amount. And then we transfer it to the actual task. This is essentially transfer learning where we use it to initialize the model of another supervised learning task.</p><p><span class="timestamp">[00:12:14]</span>
And we really use what we learned in an unsupervised way to extract features such that we can add another classifier on top, typically a neural network or prior machine learning methods such as support vector machines. Often we limit the classifier to simple linear layers. This is because we're interested in how good are the feature representations that we learn and how generalizable are they.</p><p><span class="timestamp">[00:12:39]</span>
So if we're comparing many different surrogate tasks with each other, we don't wanna have another confounding effect by adding additional complex transformations or nonlinearity. That wouldn't essentially tell us how good or the feature representations, but it kind of adds the additional element of training those additional layers. So typically we just take the features from the unsupervised surrogate tasks and then add a linear layer to whatever supervised classification task we'd like.</p><p><span class="timestamp">[00:13:08]</span>
Here's an example from the rotation prediction. This shows three different tasks, classification, detection, and segmentation. Typically we show what the performance is using all the labeled data. For example, here you could see the row labeled as image net labels. We can then compare it to a whole host of different surrogate tasks.</p><p><span class="timestamp">[00:13:30]</span>
Here you see things like context prediction, jigsaw puzzles, colorization and then from this paper, rotation prediction. What you can see is that the performance not just on classification but even object detection, is extremely competitive to image net labels alone. That is, we can actually learn features that are almost as close to image net learned features which actually use labels to drive the cross-entropy loss.</p><p><span class="timestamp">[00:13:58]</span>
This is incredibly amazing and only recently have we been able to do this. Another surrogate task that has achieved extremely good performance recently is instance discrimination. Specifically, we'll take an image such as that of a bird on the top and perform augmentation in two different ways. Again, these data augmentation algorithms are randomized.</p><p><span class="timestamp">[00:14:21]</span>
That is you can apply different amounts of color jitter, different types of rotation, different cropping and so on every time you run it. And so will perform two different augmentations with different parameters for the same image. We'll also have negative examples that are not the same image. Note that we're not saying it's not the same class or category.</p><p><span class="timestamp">[00:14:41]</span>
We can also have other birds and so on. It's just a different image, that is why it's called instance discrimination. Will take all of these images and feed them through an encoder neural network that extracts features. And then we'll essentially set up a classification task where the features between the two augmentations of the same image should be driven together.</p><p><span class="timestamp">[00:15:03]</span>
And the features between augmentation 1 and the negative examples should be driven apart. This can be done with dot product or similarity comparison between the different features similar to how we did this in few shot learning. And so what we have here is positive example which is the same image augmented in a different way and negative examples which are all other images.</p><p><span class="timestamp">[00:15:26]</span>
There are some interesting questions here of where the negative examples should come from. And we'd like to consider things like efficiency for example, we don't wanna re-compute all the features across our large unlabeled data set just for the purpose of getting negative examples. We also want to have some nice characteristics of negative examples for example, they shouldn't be too easy or too hard and so on.</p><p><span class="timestamp">[00:15:49]</span>
In fact, there's a lot of research that we won't talk about here that tries to even select what negative examples should we subsample from the larger unlabeled data set. There are several ways to extract the negatives. Here we show, two methods, on the left, we can have an end to end method where we essentially have an encoder that's shared.</p><p><span class="timestamp">[00:16:09]</span>
And we have the key which are the negatives and the query. And what we can do is essentially just within a mini batch use all the other examples in the mini batch as negatives and perform end-to-end the gradient updates to the encoder across all of the examples in the mini batch.</p><p><span class="timestamp">[00:16:28]</span>
In other words, here we're just using the mini batch items that are not the current image that we're focusing on as the negatives. There's some downsides though, because this ties the number of negatives that you're sampling from to the mini batch size. If your mini batch size is too small then you won't have that many negatives or your negatives may not be diverse.</p><p><span class="timestamp">[00:16:49]</span>
In the middle we see a memory bank approach. Rather than sampling from the mini match, we could try to store negatives across the iteration. In a memory bank, specifically a queue, in order to make the sampling of negative examples easy and efficient without having to redo feature extraction.</p><p><span class="timestamp">[00:17:09]</span>
Every time on the large unlabeled data set, we'll use the notion of a memory bank. Specifically, we'll use a queue that comes from previous mini batches which holds the features extracted from those mini batches. So given a new mini batch of data, let's say containing this bird, we'll feed it to the feature extractor.</p><p><span class="timestamp">[00:17:28]</span>
And we'll actually at the end of this iteration, put it in to the queue. So we'll pop out older items and replace them with these newer features. And in future iterations when we sample negatives will actually just sample images from this queue now, the key idea is that we don't have to do any extra feature extraction because as the iterations go by, we've already extracted those features since we need them for the back propagation.</p><p><span class="timestamp">[00:17:55]</span>
And we're just storing them so that we can later use them without having to recompute them. There's some issues here that might occur for example, the features might be stale if you're pulling elements from weigh in the front of the queue, which means that they're very old. And what we have is that these features are extracted using a long number of iterations away in terms of the weights which have since been updated as the iterations went by, then the feature space is no longer the same.</p><p><span class="timestamp">[00:18:23]</span>
There might be some staleness in the feature space but actually, it turns out not to really matter because this queue won't be that large compared to the very large amount of data sets that we have. In order to alleviate this we can also use the idea of an exponential moving average of weights.</p><p><span class="timestamp">[00:18:40]</span>
This is similar to what we've seen before and here is called a Momentum Encoder. The key idea is we want the key encoder to move slowly so that when we put them into the memory bank and use them to against the queries It won't be as different. Here the key encoder is set to M, which is a hyper parameter often set to 0.999 times the parameters of the key encoder plus 1 minus m times the parameter of the query encoder.</p><p><span class="timestamp">[00:19:07]</span>
Here only the gradients flow through the query encoder, so only those are updated. Really the momentum encoder is just a moving average of the query encoder. Again, this slows down its evolution for the key encoder so that essentially when using it Within a memory bank across iterations, it won't be as different.</p><p><span class="timestamp">[00:19:26]</span>
This method has turned out to be extremely effective. Specifically if we learn unsupervised feature representations on the image net data, and then we freeze those features and learn an additional linear layer whose parameters are optimized using image net labels. We get actually quite close in performance. That is we get 71.1% accuracy as opposed to 76.5 if we jointly train the features and the classifier using all the labels, again, we're only using labels for the 71.1% accuracy to train the linear classifier on top of the frozen features that were learned in an unsupervised way.</p><p><span class="timestamp">[00:20:05]</span>
So this is quite surprising, and only recently have we been able to achieve such strong performance. And what's even better is that these features tend to generalize better to other tasks. If we can see for the voc object detection tasks, we actually achieve higher performance using instance discrimination.</p><p><span class="timestamp">[00:20:23]</span>
Again, this shows that features that you learn in an unsupervised way when used to initialize other tasks such as object detection are actually more generalizable in some sense, which is quite surprising and exciting to see. In summary, there's a large number of surrogate tasks and variations that we can use to learn really good feature representations using unlabeled data alone.</p><p><span class="timestamp">[00:20:45]</span>
This includes contrast of losses which work across image patches or context or instance discrimination. And there's many different types of loss functions or training regimes that we can apply some of them more efficient than others. The two that have become dominant and extremely effective are for unsupervised learning.</p><p><span class="timestamp">[00:21:03]</span>
Contrastive losses and when we have semi supervised learning, pseudo labeling losses, where we have essentially the learned model applied to the labeled data, making predictions on the unlabeled data and that gets used to drive a cross entropy loss. You can also use soft knowledge distillation where you don't make the prediction of one hot for the pseudo-label.</p><p><span class="timestamp">[00:21:26]</span>
And I haven't covered all of these methods but a lot of these methods work and it's not clear which one is the best currently. What we do know is that data augmentation is now key. These methods are used across almost all of these unsupervised learning and semi-supervised learning methods.</p><p><span class="timestamp">[00:21:42]</span>
And maybe unfortunately, methods tend to be sensitive to the choice of data augmentation. So there's a lot of recent work exploring how we can automatically learn data augmentation or be able to figure out at least, what data augmentation to use. Overall, these advances have been extremely exciting and have really only occurred recently.</p><p></p>
          </div>
        </div>
      
    </div>
  </div>
  <script src="../js/script.js"></script>
</body>
</html>