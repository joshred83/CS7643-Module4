# Quiz: Introduction to Unsupervised, Semi-Supervised, and Few-Shot Learning

---

### Question 1 (True/False)  
In few-shot learning, it is common to assume access to a large amount of unlabeled data.

- True  
- False  

---

### Question 2 (Multiple Choice)  
What is the core idea behind semi-supervised learning?

- Use only labeled data to perform clustering  
- Use self-supervised tasks to generate reward signals  
- Combine a small amount of labeled data with a large amount of unlabeled data  
- Learn representations only from surrogate tasks  

---

### Question 3 (Multiple Select)  
Which of the following are traditional unsupervised learning tasks mentioned in the lecture?

- Density estimation  
- Clustering  
- Meta-learning  
- Supervised contrastive learning  

---

### Question 4 (Multiple Choice)  
What is the key motivation behind using pseudo labels in semi-supervised learning?

- To reduce computational cost during training  
- To generate labeled examples from confident predictions on unlabeled data  
- To replace the need for any labeled data  
- To tune hyperparameters for the loss function  

---

### Question 5 (True/False)  
Self-supervised learning uses human-annotated labels to guide feature learning.

- True  
- False  

---

### Question 6 (Multiple Select)  
What are some of the challenges in feature learning from unlabeled data?

- Selecting appropriate loss functions  
- Designing surrogate tasks that are neither too easy nor too hard  
- Minimizing overfitting with small datasets  
- Learning a metric with labeled anchors  

---

### Question 7 (Multiple Choice)  
What is a “surrogate task” in self-supervised learning?

- A data augmentation pipeline for labeled classification  
- A task that is designed to force the network to learn representations, even though the task itself is artificial  
- A reinforcement learning policy initialized with human preferences  
- A contrastive loss computed over cluster assignments  

---

### Question 8 (True/False)  
Metric learning is a form of unsupervised learning that assumes human-annotated pairwise similarities.

- True  
- False  

---

### Question 9 (Multiple Select)  
Which of the following strategies are used in semi-supervised learning as described in the lecture?

- Using strong and weak augmentations  
- Cross-entropy loss with hard pseudo labels  
- Training exclusively on confidently labeled examples  
- Using data to self-generate soft targets for knowledge distillation  

---

### Question 10 (Multiple Choice)  
What is the motivation behind meta-learning in few-shot scenarios?

- To maximize entropy of predictions on test data  
- To encode time-based sequence priors into models  
- To learn an initialization that adapts well to new tasks with few training steps  
- To cluster examples based on learned features  
