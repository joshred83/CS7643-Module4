# Answer Key: Introduction to Reinforcement Learning

---

### Question 1  
**Correct Answer:** False  
**Explanation:**  
Unlike supervised learning, reinforcement learning does not rely on labeled data.  
> "We will not receive supervision in the form of the correct decision... instead, we will only receive evaluative feedback in the form of reward for the decision..."&#8203;:contentReference[oaicite:0]{index=0}

---

### Question 2  
**Correct Answer:** Sequential decision-making in an environment with evaluative feedback  
**Explanation:**  
This definition is stated explicitly in the lecture.  
> "Reinforcement learning can be defined in one sentence as a sequential decision making in an environment with evaluative feedback."&#8203;:contentReference[oaicite:1]{index=1}

---

### Question 3  
**Correct Answers:** The reward signal may be delayed, The policy affects future data distribution  
**Explanation:**  
RL faces unique challenges like delayed rewards and non-stationary data caused by policy updates.  
> "The reward may be delayed and it can only happen at the end of the task..."  
> "Any updates made to the policy... will change the data distribution... making this distribution non stationary."&#8203;:contentReference[oaicite:2]{index=2}

---

### Question 4  
**Correct Answer:** The next observation and a reward  
**Explanation:**  
The agent receives both the new observation and the reward after taking an action.  
> "...the agent will receive an observation... it will execute an action... and produce a new observation... as well as a reward..."&#8203;:contentReference[oaicite:3]{index=3}

---

### Question 5  
**Correct Answer:** False  
**Explanation:**  
The data distribution is non-stationary because the policy changes what data the agent sees.  
> "...will change the data distribution of states and rewards... making this distribution non stationary."&#8203;:contentReference[oaicite:4]{index=4}

---

### Question 6  
**Correct Answer:** Feedback in the form of a reward based only on the action taken  
**Explanation:**  
Only the actions taken receive feedback, not all possible actions.  
> "Evaluative feedback means that the agent... receive rewards... only for the actions that it did take and not for the actions that did not take."&#8203;:contentReference[oaicite:5]{index=5}

---

### Question 7  
**Correct Answers:** Robotic control, Atari game playing, Board games like Go  
**Explanation:**  
These specific applications are mentioned in the lecture.  
> "Here is an instance of a robotic control task..."  
> "RL applied to learn how to play Atari video games..."  
> "RL has also been applied to games like go..."&#8203;:contentReference[oaicite:6]{index=6}

---

### Question 8  
**Correct Answer:** False  
**Explanation:**  
Only actions that are actually taken receive rewards.  
> "...the agent is supposed to pick actions and receive rewards... only for the actions that it did take and not for the actions that did not take."&#8203;:contentReference[oaicite:7]{index=7}

---

### Question 9  
**Correct Answer:** Some states may be seen only once  
**Explanation:**  
In real-world settings, agents may encounter states only once, making learning difficult.  
> "...the agent will see certain states only once and never again in his lifetime, making it difficult to learn from past mistakes."&#8203;:contentReference[oaicite:8]{index=8}

---

### Question 10  
**Correct Answer:** Maximize long-term accumulated reward  
**Explanation:**  
The core objective of the agent is long-term reward maximization.  
> "The objective of this agent is to maximize the reward it will get from the environment in the long run."&#8203;:contentReference[oaicite:9]{index=9}
