# Quiz: Few-Shot Learning

---

### Question 1 (True/False)  
Few-shot learning assumes access to many labeled examples per class at inference time.

- True  
- False  

---

### Question 2 (Multiple Choice)  
What is the main goal of meta-training in the context of few-shot learning?

- To pre-train a classifier across all possible test classes  
- To learn task-agnostic representations via unsupervised pretraining  
- To simulate test conditions using tasks constructed from base classes  
- To maximize training set accuracy for individual categories  

---

### Question 3 (Multiple Select)  
Which of the following are strategies used to prevent overfitting during fine-tuning in few-shot learning?

- Freezing the feature extractor  
- Using cosine classifiers instead of fully connected layers  
- Training on thousands of examples per class  
- Applying early stopping and hyperparameter tuning  

---

### Question 4 (Multiple Choice)  
In cosine similarity-based classification, what is primarily compared between input features and class prototypes?

- Their absolute magnitudes  
- Their Euclidean distance  
- Their angular separation (directional similarity)  
- Their softmax-normalized dot products  

---

### Question 5 (Multiple Select)  
Which of the following are core components of a prototypical network?

- Feature extractor shared across support and query sets  
- One-hot encoding of query items  
- Mean embeddings of each class in the support set  
- Learned reward functions for each query  

---

### Question 6 (True/False)  
Prototypical networks compare each query item to every example in the support set individually.

- True  
- False  

---

### Question 7 (Multiple Choice)  
How does a matching network make predictions during inference?

- By comparing query embeddings to per-class mean vectors  
- By maximizing cosine similarity with the support set embeddings  
- By computing a dot product between a query and a learned classifier head  
- By classifying via majority vote from nearest labeled neighbors  

---

### Question 8 (Multiple Select)  
Which challenges or limitations are associated with fine-tuning-based few-shot learning?

- It lacks task-specific awareness during meta-training  
- It requires large support sets to work effectively  
- It is sensitive to hyperparameter choices  
- It cannot generalize to new classes  

---

### Question 9 (Multiple Choice)  
What aspect of meta-learning does MAML specifically aim to optimize?

- The convergence speed of the outer loop  
- The pre-training accuracy on base tasks  
- The initialization of parameters for rapid adaptation  
- The complexity of the LSTM update rule  

---

### Question 10 (True/False)  
Gradient descent can be viewed as a differentiable computation graph suitable for meta-learning.

- True  
- False  

---

### Question 11 (Multiple Choice)  
What does the Meta-LSTM approach learn that MAML does not?

- How to initialize parameters before adaptation  
- A task-specific regularizer  
- A learnable update rule conditioned on gradients  
- The number of steps required for convergence  

---

### Question 12 (Multiple Select)  
What are advantages of learning initialization via MAML compared to learning an explicit update rule?

- Simpler optimization  
- Better theoretical convergence guarantees  
- Higher flexibility in modeling long-range dependencies  
- Less overfitting when applied to small support sets  
